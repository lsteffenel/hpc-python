{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lsteffenel/hpc-python/blob/master/dask/introduction_dask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_zOTwS3-SSx"
      },
      "source": [
        "![fig_dask](https://miro.medium.com/max/1000/1*D6mSsdWECFLn6wJne4VTjg.png)\n",
        "\n",
        "# <font color=\"red\">Que représente Dask ?</font>\n",
        "\n",
        "- Une bibliothèque flexible pour le calcul parallèle en Python qui facilite la construction de workflows intuitifs pour l'ingestion et l'analyse de grands ensembles de données distribués.\n",
        "- Un outil d'analyse parallèle natif conçu pour s'intégrer parfaitement avec NumPy, Pandas et Scikit-Learn.\n",
        "- Une bibliothèque de parallélisation *out-of-core* (les données sont lues en mémoire depuis le disque au fur et à mesure des besoins) qui s'intègre parfaitement aux structures de données NumPy et Pandas existantes pour répondre aux besoins suivants :\n",
        "     * **L'ensemble de données disponible ne tient pas en mémoire d'une seule machine.**\n",
        "     * **La tâche de traitement des données est chronophage et doit être mise à l'échelle et accélérée.**\n",
        "- Orchestre des threads ou processus parallèles pour nous et accélère les temps de traitement.\n",
        "   - Fonctionne en distribuant les gros calculs et en les décomposant en plus petits calculs via un ordonnanceur de tâches et des travailleurs de tâches.\n",
        "\n",
        "Dask est composé de plusieurs composants et API différents, qui peuvent être catégorisés en trois couches : l'ordonnanceur, les API de bas niveau et les API de haut niveau.\n",
        "\n",
        "- Dask fournit quelques constructions de haut niveau appelées Dask Bags, Dask DataFrames et Dask Arrays. Elles offrent une interface facile à utiliser pour paralléliser de nombreuses transformations de données typiques dans les workflows d'apprentissage automatique (ML).\n",
        "- Dask permet la création de graphes d'exécution de tâches hautement personnalisés grâce à leur API Python étendue (par ex., `dask.delayed`) et à l'intégration avec les structures de données existantes.\n",
        "\n",
        "![fig_layers](http://bicortex.com/bicortex/wp-content/post_content//2019/06/Dask_APIs_Architecture.png)  \n",
        "**Source de l'image** : bicortex.com\n",
        "\n",
        "Le diagramme ci-dessous décrit les étapes suivies par Dask pour manipuler les données.\n",
        "\n",
        "- L'opération est décomposée en une séquence d'opérations sur des partitions plus petites de nos données (sans avoir à charger tout l'ensemble de données en mémoire).\n",
        "- Dask lit chaque partition au fur et à mesure des besoins et calcule les résultats intermédiaires.\n",
        "- Les résultats intermédiaires sont agrégés dans le résultat final.\n",
        "- Dask gère toute cette séquence en interne pour nous.\n",
        "- Sur une seule machine, Dask peut utiliser des threads ou des processeurs pour paralléliser ces opérations.\n",
        "\n",
        "![fig_proc](https://www.nvidia.com/content/dam/en-zz/Solutions/glossary/data-science/dask/dask-pic1.png)  \n",
        "\n",
        "\n",
        "**Avantages de l'utilisation de Dask**\n",
        "\n",
        "- Entièrement implémenté en Python et met nativement à l'échelle NumPy, Pandas et scikit-learn.\n",
        "- Peut être utilisé efficacement pour travailler avec des ensembles de données moyens sur une seule machine et de grands ensembles de données sur un cluster.\n",
        "- Peut être utilisé comme un framework général pour paralléliser la plupart des objets Python.\n",
        "- Présente une configuration et un coût de maintenance très faibles.\n",
        "\n",
        ">Dask fournit des collections de haut niveau Array, Bag et DataFrame qui imitent NumPy, les listes et Pandas mais peuvent opérer en parallèle sur des ensembles de données qui ne rentrent pas en mémoire principale. Les collections de haut niveau de Dask sont des alternatives à NumPy et Pandas pour les grands ensembles de données.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8pHFIBI-SSx"
      },
      "source": [
        "**Rappel sur les processus et les threads**\n",
        "\n",
        "- Un **processus** est une exécution de programme.\n",
        "- Un **thread** est une séquence d'exécution unique au sein du processus.\n",
        "- Un processus peut contenir plusieurs threads.\n",
        "- Les threads sont utilisés pour des tâches légères, tandis que les processus sont utilisés pour des tâches plus « lourdes ».\n",
        "\n",
        "\n",
        "**Python classique ne peut exécuter qu'un seul thread à la fois.**\n",
        "\n",
        ">Dask offre une méthode facile et cohérente pour paralléliser les calculs qui s'étend d'un simple ordinateur portable à des clusters de milliers de cœurs. Il repose sur un ordonnanceur de tâches qui distribue les appels de fonctions Python sur plusieurs threads, processus ou nœuds de cluster.\n",
        "\n",
        "\n",
        "![threads](https://pediaa.com/wp-content/uploads/2018/07/Difference-Between-Process-and-Thread-Comparison-Summary-684x1024.jpg)  \n",
        "**Source de l'image** : pediaa.com\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGFobdE1-SSx"
      },
      "source": [
        "### Installation / importation de modules\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gTw00xx-SSx"
      },
      "outputs": [],
      "source": [
        "!python -m pip install dask[complete]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7Bj3V6F-SSy"
      },
      "outputs": [],
      "source": [
        "!pip install memory_profiler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlWFzeaGvPmc"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uktcOPYqt8Cn"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "import dask\n",
        "import dask.array as da\n",
        "import dask.dataframe as dd\n",
        "from dask.diagnostics import ProgressBar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Q77FBnF-SSy"
      },
      "outputs": [],
      "source": [
        "print(f\"Numpy version:  {np.__version__}\")\n",
        "print(f\"Pandas version: {pd.__version__}\")\n",
        "print(f\"Dask   version: {dask.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Clp5fTHu-SSy"
      },
      "outputs": [],
      "source": [
        "from memory_profiler import memory_usage\n",
        "import memory_profiler\n",
        "%load_ext memory_profiler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ng_rnKFc-SSz"
      },
      "source": [
        "## Détermination des informations du système"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzXQNijE-SSz"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "def convert_size(size):\n",
        "    \"\"\"\n",
        "      Convert from KB to another unit.\n",
        "    \"\"\"\n",
        "    if (size == 0):\n",
        "       return '0B'\n",
        "    size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\")\n",
        "    i = int(math.floor(math.log(size,1024)))\n",
        "    p = math.pow(1024,i)\n",
        "    s = round(size/p,2)\n",
        "    return \" \".join([str(s),size_name[i]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AiuYwciT-SSz"
      },
      "outputs": [],
      "source": [
        "import platform\n",
        "import psutil\n",
        "\n",
        "print(\"=\"*20, \"System Information\", \"=\"*20)\n",
        "uname = platform.uname()\n",
        "print(f\"           System: {uname.system}\")\n",
        "print(f\"        Node Name: {uname.node}\")\n",
        "print(f\"          Release: {uname.release}\")\n",
        "print(f\"          Version: {uname.version}\")\n",
        "print(f\"          Machine: {uname.machine}\")\n",
        "print(f\"        Processor: {uname.processor}\")\n",
        "print(\"=\"*20, \"CPU Information\", \"=\"*20)\n",
        "cpufreq = psutil.cpu_freq()\n",
        "print(\"# logical cores = # physical cores times # threads \")\n",
        "print(\"                    that can run on each physical core.\")\n",
        "print(f\"   Physical cores: {psutil.cpu_count(logical=False)}\")\n",
        "print(f\"    Logical cores: {psutil.cpu_count(logical=True)}\")\n",
        "print(f\"Current frequency: {psutil.cpu_freq().current}\")\n",
        "print(f\"    Min frequency: {psutil.cpu_freq().min}\")\n",
        "print(f\"    Max frequency: {psutil.cpu_freq().max}\")\n",
        "print(\"=\"*20, \"Memory Information\", \"=\"*20)\n",
        "svmem = psutil.virtual_memory()\n",
        "print(f\"     Total memory: {convert_size(svmem.total)}\")\n",
        "print(f\" Available memory: {convert_size(svmem.available)}\")\n",
        "svmem = psutil.virtual_memory()\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sur Colab on a généralement 1 coeur physique (2 coeurs logiques). Ça permettra de faire quelques tests de parallélisme, mais limités. Si vous lancez le code sur votre propre machine, vous pouvez obtenir des résultats bien plus intéressants."
      ],
      "metadata": {
        "id": "rIRr9124UGcW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCdhmJP0-SSz"
      },
      "source": [
        "### Configuration de la barre de progression\n",
        "\n",
        "- Vous pouvez utiliser la barre de progression intégrée de Dask pour suivre l'avancement de n'importe quel appel `get()` ou `compute()`.\n",
        "- Ici, nous utiliserons l'enregistrement global où la barre de progression s'affichera pour tous les calculs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UecEnOsa-SSz"
      },
      "outputs": [],
      "source": [
        "from dask.diagnostics import ProgressBar\n",
        "pbar = ProgressBar()\n",
        "pbar.register()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-cU2qC8-SSz"
      },
      "source": [
        "# <font color=\"red\">Paralléliser le code avec `dask.delayed`</font>\n",
        "\n",
        "- Une méthode simple pour paralléliser le code.\n",
        "- Permet aux utilisateurs de retarder les appels de fonctions dans un graphe de tâches avec dépendances.\n",
        "- Des systèmes comme `dask.dataframe` sont construits avec `dask.delayed`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9DdwpYM-SSz"
      },
      "source": [
        "**Exemple Simple**\n",
        "\n",
        "Considerez les fonctions suivantes :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMUztQOB-SSz"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def increment(x):\n",
        "    time.sleep(1.0)\n",
        "    return x + 1\n",
        "\n",
        "def double(x):\n",
        "    time.sleep(1.0)\n",
        "    return 2 * x\n",
        "\n",
        "def add(x, y):\n",
        "    time.sleep(1.0)\n",
        "    return x + y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwEr2vQc-SSz"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "x = increment(1)\n",
        "y = increment(2)\n",
        "z = add(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regardez surtout le temps d'exécution (**Wall time**). Nous allons utiliser ça comme paramètre pour les comparaisons futures."
      ],
      "metadata": {
        "id": "JpxNUGmvUqGH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrO5LJpQ-SSz"
      },
      "source": [
        "Pour paralléliser ce code en Dask, nous allons utiliser le décorateur `dask.delayed` sur les fonctions `increment` et `add`.\n",
        "- En décorant les fonctions, nous enregistrons ce que nous voulons calculer sous forme de tâches dans des graphes qui seront exécutés plus tard sur du matériel parallèle.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37GiL0E8-SS0"
      },
      "outputs": [],
      "source": [
        "xd = dask.delayed(increment)(1)\n",
        "yd = dask.delayed(increment)(2)\n",
        "zd = dask.delayed(add)(xd, yd)\n",
        "zd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56H1_1K5-SS0"
      },
      "source": [
        "- Quand nous appelons la version retardée en passant les arguments, exactement comme avant, la fonction originale n'est pas encore exécutée.\n",
        "- Un objet *delayed* est créé, qui garde la trace de la fonction à appeler et des arguments à lui passer.\n",
        "- Nous utilisons la méthode `visualize` (qui repose sur le package `graphviz`) qui fournit une représentation visuelle des opérations effectuées.\n",
        "\n",
        "**ATTENTION** : la création des *delayed* ne lance pas automatiquement leur exécution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "xNwvnM5X-SS0"
      },
      "outputs": [],
      "source": [
        "zd.visualize(rankdir='LR')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdA7mg1c-SS0"
      },
      "source": [
        "- Notez que nous n'avons pas encore calculé **total** physiquement.\n",
        "- Nous devons appliquer la méthode `compute` pour obtenir le résultat.\n",
        "- <font color=\"red\">C'est seulement à ce moment que les données sont chargées en mémoire pour les calculs</font>.\n",
        "- Les calculs sont effectués en utilisant un pool de threads local."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJRShsgU-SS0"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "dask.compute(zd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zizg8rem-SS0"
      },
      "source": [
        "**Utilisation de `delayed` dans des boucles**\n",
        "\n",
        "Considérez le code séquentiel avec deux boucles *for* :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IX6Rlr0V-SS0"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "n = 10\n",
        "data = [i+1 for i in range(n)]\n",
        "\n",
        "out = list()\n",
        "for x in data:\n",
        "    y = increment(x)\n",
        "    z = double(y)\n",
        "    out.append(z)\n",
        "\n",
        "total = 0\n",
        "for z in out:\n",
        "    total = add(total, z)\n",
        "\n",
        "total"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnvgwGNc-SS0"
      },
      "source": [
        "Nous pouvons paralléliser le code ci-dessus en utilisant le décorateur `delayed` :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKKXTvw_-SS0"
      },
      "outputs": [],
      "source": [
        "n = 10\n",
        "data = [i+1 for i in range(n)]\n",
        "\n",
        "out = list()\n",
        "for x in data:\n",
        "    y = dask.delayed(increment)(x)\n",
        "    z = dask.delayed(double)(y)\n",
        "    out.append(z)\n",
        "\n",
        "totald = 0\n",
        "for z in out:\n",
        "    totald = dask.delayed(add)(totald, z)\n",
        "\n",
        "totald"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zm-AlHg0-SS0"
      },
      "source": [
        "Nous pouvons aussi obtenir la représentation visuelle via un graphe de tâches.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9tJrGip-SS1"
      },
      "outputs": [],
      "source": [
        "totald.visualize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "horU8AHB-SS1"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "dask.compute(totald)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTI1TEOE-SS1"
      },
      "source": [
        "### Exercice 1\n",
        "\n",
        "Utilisez le décorateur `delayed` pour paralléliser le code ci-dessous :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35h2fEpd-SS1"
      },
      "outputs": [],
      "source": [
        "def is_odd(x):\n",
        "    return x%2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyskTUeu-SS1"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "n = 10\n",
        "data = [i+1 for i in range(n)]\n",
        "\n",
        "results = list()\n",
        "\n",
        "for x in data:\n",
        "    if is_odd(x):\n",
        "        y = double(x)\n",
        "    else:\n",
        "        y = increment(x)\n",
        "    results.append(y)\n",
        "\n",
        "total = sum(results)\n",
        "print(total)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#VOTRE CODE ICI"
      ],
      "metadata": {
        "id": "O5NnsQWJHjCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmK_FIy1-SS1"
      },
      "source": [
        "### Exemple : Mots palindromiques\n",
        "\n",
        "- Un mot palindromique est un mot dont les caractères se lisent de la même façon à l'envers qu'à l'endroit.\n",
        "- Quelques exemples de palindromes sont `redivider`, `deified`, `civic`, `radar`, `level`, `rotor`, `kayak`, `reviver`, `racecar`, `madam`, et `refer`.\n",
        "\n",
        "Nous voulons trouver le nombre de palindromes dans une liste de mots.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZKBGw34-SS2"
      },
      "outputs": [],
      "source": [
        "def is_palindrome(s):\n",
        "    return s.upper() == s.upper()[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTxSzRJx-SS2"
      },
      "outputs": [],
      "source": [
        "list_words = [\n",
        "    'complete', 'abstraction', 'from', 'compass', 'sights', 'sounds',\n",
        "    'Human', 'shapes', 'interferences', 'troubles', 'joys', 'were',\n",
        "    'they', 'were', 'there', \"man\", 'seemed', 'shaded', 'hemisphere',\n",
        "    'globe', 'sentient', 'being', 'save', 'himself', \"rather\",\n",
        "    \"Abba\", \"Aibohphobia\", \"Bib\", \"Bob\", \"Civic\", \"Deified\",\n",
        "    \"Detartrated\", \"Dewed\", \"Eve\", \"Hannah\", \"Kayak\", \"Level\",\n",
        "    \"Madam\", \"Malayalam\", \"Minim\", \"Mom\", \"Murdrum\", \"Noon\", \"Nun\",\n",
        "    \"Otto\", \"Peep\", \"Pop\", \"Racecar\", \"Radar\", \"Redder\", \"Refer\",\n",
        "    \"Repaper\", \"Rotator\", \"Rotavator\", \"Rotor\", \"Sagas\",\n",
        "    \"Sis\", \"Solo\", \"Stats\", \"Tattarrattat\", \"Tenet\",\n",
        "    'redivider', 'deified', 'civic', 'radar', 'level',\n",
        "    'Being', 'not', 'without', 'frequent', 'consciousness',\n",
        "    'that', 'there', 'was', 'some', 'charm', 'this', 'life', 'stood',\n",
        "    'still', 'after', 'looking', 'sky', 'useful', 'instrument',\n",
        "    'regarded', 'appreciative', 'spirit', 'work', 'art',\n",
        "    'superlatively', 'beautiful', 'moment', 'seemed',\n",
        "    'impressed', 'with', 'speaking', 'loneliness', 'scene',\n",
        "    \"brother\", \"system\", \"SISteR\", \"TEXT\", \"paREnts\", \"python\",\n",
        "    \"Numpy\", \"Dask\", \"PanDaS\"\n",
        "]\n",
        "\n",
        "len(list_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ePoddKr-SS2"
      },
      "source": [
        "**Code simple en Python**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0I87aAFy-SS2"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "palindromes_py = [is_palindrome(s) for s in list_words]\n",
        "total_py = sum(palindromes_py)\n",
        "total_py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKgvlXWo-SS2"
      },
      "source": [
        "**Avec Dask delayed**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEDdtmvU-SS2"
      },
      "outputs": [],
      "source": [
        "palindromes_da = [dask.delayed(is_palindrome)(s) for s in list_words]\n",
        "total_da = dask.delayed(sum)(palindromes_da)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0-twL0z-SS2"
      },
      "outputs": [],
      "source": [
        "total_da.visualize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRMo5bXK-SS2"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "result = total_da.compute()\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quelle horreur, Dask semble bien plus lent !!!\n",
        "La raison est que le traitement avec `delayed` n'a pas la bonne granularité.\n",
        "\n",
        "On peut essayer d'utiliser une structure de données propre à Dask (les `bag`), our voir si ça peut s'améliorer."
      ],
      "metadata": {
        "id": "jsWzNqAwW6aW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_xy1yBV-SS2"
      },
      "source": [
        "Si nous utilisons Dask Bag, nous effectuons les mêmes calculs plus rapidement :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_Ouvm-E-SS2"
      },
      "outputs": [],
      "source": [
        "import dask.bag as db\n",
        "bag = db.from_sequence(list_words)\n",
        "bag.map(is_palindrome).visualize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BburINY-SS2"
      },
      "outputs": [],
      "source": [
        "%time\n",
        "result= sum(bag.map(is_palindrome).compute())\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLFGK1mY-SS3"
      },
      "source": [
        "**<font color=\"red\">Leçons à retenir</font>**\n",
        "\n",
        "- Le décorateur `delayed` ajoute une surcharge.\n",
        "- Il est préférable de ne pas l'utiliser quand une tâche nécessite peu de temps.\n",
        "- Appelez `delayed` sur la fonction et non sur le résultat.\n",
        "- Décomposez les calculs en de nombreuses pièces. Vous obtenez le parallélisme en ayant de nombreux appels *delayed*, et non en utilisant un seul : Dask ne regardera pas à l'intérieur d'une fonction décorée avec `delayed` pour paralléliser ce code en interne.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ht9Cw_Le-SS3"
      },
      "source": [
        "### Exercice 2\n",
        "\n",
        "Utilisez Dask pour paralléliser le code ci-dessous (calculs de `pi`) :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJ0DgNeL-SS3"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "import random\n",
        "\n",
        "def approximate_pi(num_samples):\n",
        "    num_points_circ = 0\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        # Select an arbitrary point in [-1,1]x[-1,1]\n",
        "        x = random.uniform(-1, 1)\n",
        "        y = random.uniform(-1, 1)\n",
        "\n",
        "        # Check if the point is inside the circle\n",
        "        if x**2 + y**2 < 1.0:\n",
        "            num_points_circ += 1\n",
        "\n",
        "    return 4 * num_points_circ / num_samples\n",
        "\n",
        "def mean(*args):\n",
        "    return sum(args) / len(args)\n",
        "\n",
        "number_samples = 10**6\n",
        "number_experiments = 10\n",
        "\n",
        "pi_approx = mean(*[approximate_pi(number_samples) for i in range(number_experiments)])\n",
        "\n",
        "print(\"Approximation of Pi: {}\".format(pi_approx))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#VOTRE CODE ICI"
      ],
      "metadata": {
        "id": "c29MHJtvHpbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAsCVnWL-SS3"
      },
      "source": [
        "# <font color=\"red\">Dask Array</font>\n",
        "\n",
        "- Les tableaux Dask coordonnent de nombreux tableaux NumPy, organisés en **chunks** dans une grille.\n",
        "    - **Parallèle** : Utilise tous les cœurs de votre ordinateur\n",
        "    - **Plus grand que la mémoire** : Permet de travailler sur des ensembles de données plus grands que la mémoire disponible en décomposant votre tableau en de nombreuses petites pièces, en opérant sur ces pièces dans un ordre qui minimise l'empreinte mémoire de votre calcul, et en fluxant efficacement les données depuis le disque.\n",
        "    - **Algorithmes par blocs** : Effectue de gros calculs en réalisant de nombreux plus petits calculs\n",
        "- Ils supportent un large sous-ensemble de l'API NumPy.\n",
        "\n",
        "![fig_array](https://miro.medium.com/max/1388/1*JfQnXJ5_R104bPyE8_XhwQ.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NliD4RH8-SS3"
      },
      "source": [
        "**Créer un tableau Dask**\n",
        "\n",
        "- Créez un tableau 20000x20000 de nombres aléatoires, représenté par de nombreux tableaux NumPy de taille 1000x1000 (ou plus petits si le tableau ne peut pas être divisé uniformément).\n",
        "- Il y a 400 (20x20) tableaux NumPy de taille 1000x1000.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kz6wxzUk-SS3"
      },
      "outputs": [],
      "source": [
        "x = da.random.random((10000, 40000), chunks=(1000, 1000))\n",
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoDGzCcx-SS3"
      },
      "source": [
        "Le tableau :\n",
        "- Fait 2,98 Gb\n",
        "- Est organisé en 400 **chunks** de tableaux NumPy `1000x1000`.\n",
        "- Chaque chunk fait 7,64 Mb\n",
        "\n",
        "Des informations similaires peuvent être obtenues via :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6dkDC7x-SS3"
      },
      "outputs": [],
      "source": [
        "print(f\"     Type: {type(x)}\")\n",
        "print(f\"    Shape: {x.shape}\")\n",
        "print(f\"     Size: {x.size}\")\n",
        "print(f\"Num bytes: {x.nbytes} B or {convert_size(x.nbytes)}\")\n",
        "print(f\"   Chunks: {x.chunks}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3pZG4yz-SS3"
      },
      "source": [
        "Nous pouvons utiliser la syntaxe NumPy :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cS-gxofR-SS4"
      },
      "outputs": [],
      "source": [
        "y = 2.0 + x.T\n",
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leFY-HLl-SS4"
      },
      "outputs": [],
      "source": [
        "mu = x.mean(axis=0)\n",
        "mu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdaFmYjb-SS4"
      },
      "outputs": [],
      "source": [
        "z = y[::2, 5000:].mean(axis=1)\n",
        "z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jv1JwWUJ-SS4"
      },
      "outputs": [],
      "source": [
        "z.visualize(rankdir=\"LR\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VtTcAWl-SS4"
      },
      "source": [
        "Utilisez la fonction **`compute()`** si vous voulez votre résultat sous forme de tableau NumPy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpzYIcJn-SS4"
      },
      "outputs": [],
      "source": [
        "mu[0].compute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "er6x7-bF-SS4"
      },
      "outputs": [],
      "source": [
        "w = z.compute()\n",
        "print(type(w), w.shape )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBX10jFi-SS4"
      },
      "source": [
        "**Faire persister les données en mémoire**\n",
        "\n",
        "- Si vous disposez de la RAM disponible pour votre jeu de données, vous pouvez persister les données en mémoire.\n",
        "- Cela permet aux calculs futurs d'être beaucoup plus rapides.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wmPu4mL-SS4"
      },
      "outputs": [],
      "source": [
        "%time y.sum().compute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcJfyh5s-SS4"
      },
      "outputs": [],
      "source": [
        "y = y.persist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grct90im-SS5"
      },
      "outputs": [],
      "source": [
        "%time y[0, 0].compute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15kcHexe-SS5"
      },
      "outputs": [],
      "source": [
        "%time y.sum().compute()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrfJpRqG-SS5"
      },
      "source": [
        "**Usage mémoire Numpy versus Dask**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgW7kdAJ-SS5"
      },
      "outputs": [],
      "source": [
        "def f_numpy():\n",
        "    x = np.random.normal(10, 0.1, size=(20000, 20000))\n",
        "    y = x.mean(axis=0)[::100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLVUKqNK-SS5"
      },
      "source": [
        "`%%memit`\n",
        "\n",
        "- Mesure l'utilisation mémoire d'une seule instruction.\n",
        "- Fournit la mémoire maximale et la croissance incrémentielle de la mémoire\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hy095aqt-SS5"
      },
      "outputs": [],
      "source": [
        "%%memit\n",
        "f_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hx9EKEiF-SS5"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "f_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfsWIUSk-SS5"
      },
      "outputs": [],
      "source": [
        "def f_dask():\n",
        "    x = da.random.normal(10, 0.1, size=(20000, 20000),\n",
        "                         chunks=(1000, 1000))\n",
        "    y = x.mean(axis=0)[::100].compute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAACmmDb-SS5"
      },
      "outputs": [],
      "source": [
        "%%memit\n",
        "f_dask()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DhOF6bq-SS5"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "f_dask()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1JlePBO-SS5"
      },
      "source": [
        "On voit que Dask utilise moins de mémoire, mais son temps d'exécution n'est pas si impressionnant.\n",
        "\n",
        "Redimensionner la taille des chunks peut améliorer les performances :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MC9L4wJX-SS6"
      },
      "outputs": [],
      "source": [
        "def f_dask2():\n",
        "    x = da.random.normal(10, 0.1, size=(20000, 20000),\n",
        "                         chunks=(2000, 500))\n",
        "    y = x.mean(axis=0)[::100].compute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ID_0Goyy-SS6"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "f_dask2()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLQLs9HA-SS6"
      },
      "source": [
        "**Dask a terminé plus rapidement, mais a utilisé plus de temps CPU total car Dask a pu paralléliser de manière transparente le calcul grâce à la taille des chunks.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBYCzOhl-SS6"
      },
      "source": [
        "**<font color=\"red\">Points à considérer</font>**\n",
        "\n",
        "- Si vos données tiennent en RAM et que vous n'êtes pas limité par les performances, alors utiliser NumPy peut être le bon choix. Dask ajoute une couche de complexité supplémentaire qui peut gêner.\n",
        "- **Si vous cherchez seulement des accélérations plutôt que de la scalabilité, envisagez d'utiliser Numba pour manipuler les tableaux NumPy.**\n",
        "- Comment choisir la taille des chunks ?\n",
        "     - Trop petits : surcharge importante.\n",
        "     - Mal alignés avec les données : lecture inefficace.\n",
        "     - Il est recommandé d'avoir une taille de chunk d'au moins 100 Mb.\n",
        "     - Choisissez une taille de chunk suffisamment grande pour réduire le nombre de chunks que Dask doit gérer (ce qui affecte la surcharge) mais aussi assez petite pour que plusieurs puissent tenir en mémoire simultanément. Dask aura souvent autant de chunks en mémoire que deux fois le nombre de threads actifs.\n",
        "\n",
        "**Éviter la sur-souscription des threads**\n",
        "     \n",
        "- Par défaut, Dask exécute autant de tâches concurrentes que vous avez de cœurs logiques.\n",
        "- Il suppose que chaque tâche consomme environ un cœur.\n",
        "- Beaucoup de bibliothèques de calcul (utilisées par Dask) sont elles-mêmes multi-threadées, ce qui peut causer des conflits et de mauvaises performances.\n",
        "- Pour de meilleures performances, nous devons spécifier explicitement l'utilisation d'un seul thread :\n",
        "\n",
        "```bash\n",
        "   export OMP_NUM_THREADS=1\n",
        "   export MKL_NUM_THREADS=1\n",
        "   export OPENBLAS_NUM_THREADS=1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kCV308E-SS6"
      },
      "source": [
        "## <font color=\"red\">Profilage mémoire</font>\n",
        "\n",
        "- Nous utilisons le package `memory_profiler` pour suivre l'utilisation mémoire.\n",
        "- Il est entièrement écrit en Python et surveille le processus qui exécute du code Python ainsi que l'utilisation mémoire ligne par ligne.\n",
        "- Nous utilisons la fonction `memory_usage()` et passons le paramètre `interval` pour la fréquence de mesure de l'utilisation mémoire.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnG-HsbX-SS6"
      },
      "outputs": [],
      "source": [
        "def sum_with_numpy():\n",
        "    # Serial implementation\n",
        "    np.arange(10**8).sum()\n",
        "\n",
        "def sum_with_dask():\n",
        "    # Parallel implementation\n",
        "    work = da.arange(10**8).sum()\n",
        "    work.compute()\n",
        "\n",
        "memory_numpy = memory_usage(sum_with_numpy, interval=0.01)\n",
        "memory_dask = memory_usage(sum_with_dask, interval=0.01)\n",
        "\n",
        "# Plot results\n",
        "plt.plot(memory_numpy, label='numpy')\n",
        "plt.plot(memory_dask, label='dask')\n",
        "plt.xlabel('Time step')\n",
        "plt.ylabel('Memory / MB')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbIr_1nn-SS6"
      },
      "source": [
        "Vous pouvez aussi utiliser les options de profilage de Dask :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tTtA_pv-SS6"
      },
      "outputs": [],
      "source": [
        "from dask.diagnostics import Profiler, ResourceProfiler\n",
        "work = da.arange(10**8).sum()\n",
        "with Profiler() as prof, ResourceProfiler(dt=0.001) as rprof:\n",
        "    result2 = work.compute()\n",
        "\n",
        "from bokeh.plotting import output_notebook\n",
        "from dask.diagnostics import visualize\n",
        "visualize([prof,rprof], output_notebook())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVYNIif2-SS6"
      },
      "outputs": [],
      "source": [
        "with ResourceProfiler(dt=0.001) as rprof2:\n",
        "    result = np.arange(10**8).sum()\n",
        "visualize([rprof2], output_notebook())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pj5mYuke-SS6"
      },
      "source": [
        "# <font color=\"red\">Dask DataFrames</font>\n",
        "\n",
        "- Pandas est excellent pour les ensembles de données tabulaires qui tiennent en mémoire.\n",
        "- Dask devient utile quand l'ensemble de données à analyser est plus grand que la RAM de votre machine.\n",
        "- Dask DataFrames :\n",
        "     - Coordonnent de nombreux DataFrames Pandas, partitionnés le long d'un index.\n",
        "     - Supportent un large sous-ensemble de l'API Pandas.\n",
        "- Une opération sur un Dask DataFrame déclenche de nombreuses opérations Pandas sur les DataFrames Pandas constitutifs, de manière à prendre en compte le parallélisme potentiel et les contraintes mémoire.\n",
        "- Parmi les opérations très rapides avec les Dask DataFrames :\n",
        "     - Opérations arithmétiques (multiplication ou addition à une Series)\n",
        "     - Agrégations courantes (`mean`, `min`, `max`, `sum`, etc.)\n",
        "     - Appel de `apply`\n",
        "     - Appel de `value_counts()`, `drop_duplicates()` ou `corr()`\n",
        "     - Filtrage avec `loc`, `isin`, et sélection ligne par ligne\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGuPjwLt-SS7"
      },
      "source": [
        "### <font color=\"green\">Exemple : Dataset des vols NYC</font>\n",
        "\n",
        "Ce dataset contient des données concernant des vols (années 1990) au départ des trois aéroports de la région de New York.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XL3oxLdO-SS7"
      },
      "source": [
        "télécharger les données :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkl-t7Hl-SS7"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "\n",
        "print(\"\\t Downloading NYC dataset...\", end=\"\\n\", flush=True)\n",
        "\n",
        "url = \"https://storage.googleapis.com/dask-tutorial-data/nycflights.tar.gz\"\n",
        "filename, header = urllib.request.urlretrieve(url, \"nycflights.tar.gz\")\n",
        "\n",
        "print(\"\\t Done!\", flush=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmmSGXCW-SS7"
      },
      "outputs": [],
      "source": [
        "!ls -lrt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRxVoJBF-SS7"
      },
      "source": [
        "Extraire les fichiers `.csv` du fichier tar.gz :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1ZEb0Xa-SS7"
      },
      "outputs": [],
      "source": [
        "import tarfile\n",
        "\n",
        "with tarfile.open(filename, mode=\"r:gz\") as flights:\n",
        "     flights.extractall(\"data/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5nXF2-3-SS7"
      },
      "outputs": [],
      "source": [
        "!ls -lrt data/nycflights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA1Ii9DY-SS7"
      },
      "source": [
        "Charger tous les fichiers dans le dataset, d'un seul coup:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebGTQG9N-SS7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "df = dd.read_csv(os.path.join(\"data\", \"nycflights\", \"*.csv\"),\n",
        "                parse_dates={\"Date\": [0, 1, 2]})\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JitcR2Po-SS7"
      },
      "source": [
        "- La représentation de l'objet DataFrame (aussi appelé *schéma*) ne contient pas de données.\n",
        "- `pandas.read_csv` lit l'intégralité du fichier avant d'inférer les types de données.\n",
        "- `dask.dataframe.read_csv` ne lit qu'un échantillon du début du fichier (ou du premier fichier). Ces types de données inférés sont ensuite appliqués lors de la lecture de toutes les partitions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sdfBtAT-SS7"
      },
      "source": [
        "Nous pouvons essayer d'afficher les premières lignes :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuJF83uP-SS8"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7p90Bm7J-SS8"
      },
      "source": [
        "Par contre, si on essaye d'afficher les dernières lignes, on peut tomber sur une erreur :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzniub_0-SS8"
      },
      "outputs": [],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Onqg-gd-SS8"
      },
      "source": [
        "En effet, il y a un problème avec les types de données de quelques colonnes.\n",
        "- Les types de données inférés à partir de l'échantillon sont incorrects.\n",
        "- Nous pouvons le corriger en relisant les fichiers et en spécifiant les types de données appropriés.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GH-Hnx-B-SS8"
      },
      "outputs": [],
      "source": [
        "df = dd.read_csv(os.path.join(\"data\", \"nycflights\", \"*.csv\"),\n",
        "                parse_dates={\"Date\": [0, 1, 2]},\n",
        "                dtype={'TailNum': str,\n",
        "                       'CRSElapsedTime': float,\n",
        "                       'Cancelled': bool})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OBJeqO0-SS8"
      },
      "outputs": [],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TMHT3EB-SS8"
      },
      "source": [
        "### <font color=\"blue\">Effectuer des opérations comme avec les `Pandas DataFrames`</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jBAMbqi-SS8"
      },
      "source": [
        "**Valeur maximale d'une colonne** :\n",
        "\n",
        "- Nous voulons maintenant calculer le maximum de la colonne `DepDelay`.\n",
        "- Avec `Pandas`, nous ferions une boucle sur chaque fichier pour trouver les maximums individuels, puis trouver le maximum final sur tous les maximums individuels.\n",
        "- `dask.dataframe` nous permet d'écrire du code semblable à Pandas qui opère sur des ensembles de données plus grands que la mémoire, en parallèle.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3cYckyf-SS8"
      },
      "outputs": [],
      "source": [
        "df.DepDelay.max().visualize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Vc3wOi1-SS8"
      },
      "outputs": [],
      "source": [
        "%time df.DepDelay.max().compute()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XxQ7VGn-SS8"
      },
      "source": [
        "Si nous faisons la même chose en `Pandas`, nous obtiendrons :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S665yjXc-SS8"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "import glob\n",
        "\n",
        "list_files = glob.glob(\"data/nycflights/*csv\")\n",
        "\n",
        "maxes = list()\n",
        "for file_name in list_files:\n",
        "    pddf = pd.read_csv(file_name)\n",
        "    maxes.append(pddf.DepDelay.max())\n",
        "\n",
        "final_max = max(maxes)\n",
        "\n",
        "print(\"Final Maximum: \", max(maxes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZarv61u-SS9"
      },
      "source": [
        "**Plotting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wftQjPG-SS9"
      },
      "outputs": [],
      "source": [
        "df[df.Dest == 'PIT'].compute().plot(kind='scatter',\n",
        "                                    x=\"DayOfWeek\",\n",
        "                                    y=\"DepDelay\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGWW_gIF-SS9"
      },
      "source": [
        "**Autres Operations et statistiques sur les vols**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jUr16g5-SS9"
      },
      "source": [
        "Nombre de vols non annulés:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMZ2jcVX-SS9"
      },
      "outputs": [],
      "source": [
        "len(df[~df.Cancelled])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oydytw61-SS9"
      },
      "source": [
        "Nombre de vols non-annulés au départ de chaque aéroport :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbB9y4Pb-SS9"
      },
      "outputs": [],
      "source": [
        "df[~df.Cancelled].groupby('Origin').Origin.count().compute()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuoHCGbW-SS9"
      },
      "source": [
        "Retard moyen au départ pour chaque jour de la semaine :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kMZpZGa-SS9"
      },
      "outputs": [],
      "source": [
        "df.groupby(\"DayOfWeek\").DepDelay.mean().compute()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k173t9iF-SS9"
      },
      "source": [
        "Regroupement par destinations et comptage :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJjVlu-2-SS9"
      },
      "outputs": [],
      "source": [
        "df.groupby(\"Dest\").count().compute()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Moyenne des retards par destination."
      ],
      "metadata": {
        "id": "7FvAYgKHbj7v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6r7qtlzn-SS9"
      },
      "outputs": [],
      "source": [
        "df.groupby(\"Dest\")[\"ArrDelay\"].mean().compute()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total des vols en retard supérieur à 30 minutes, par destination."
      ],
      "metadata": {
        "id": "qA4b2vkGbnf8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coXrEqIy-SS9"
      },
      "outputs": [],
      "source": [
        "df[df.ArrDelay+df.DepDelay>30.0].groupby(\"Dest\").Dest.count().compute()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOrJolM6-SS-"
      },
      "source": [
        "**Partage des résultats intermédiaires**\n",
        "\n",
        "- Nous effectuons parfois la même opération plusieurs fois.\n",
        "- Pour la plupart des opérations, `dask.dataframe` hache les arguments, permettant aux calculs dupliqués d'être partagés et ne calculés qu'une seule fois.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9I89G4N-SS-"
      },
      "outputs": [],
      "source": [
        "non_cancelled = df[~df.Cancelled]\n",
        "mean_delay = non_cancelled.DepDelay.mean()\n",
        "std_delay = non_cancelled.DepDelay.std()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ici, on appelle chaque transformation séparemment."
      ],
      "metadata": {
        "id": "7lQsIMlDb4la"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PW2atmqO-SS-"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "mean_delay_res = mean_delay.compute()\n",
        "std_delay_res = std_delay.compute()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_PXPpYh-SS-"
      },
      "source": [
        "Maintenant, nous passons les deux transformations à un seul appel `compute` :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjATSKRb-SS-"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "mean_delay_res, std_delay_res = da.compute(mean_delay, std_delay)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzA-lBP3-SS-"
      },
      "source": [
        "Les graphes de tâches des deux résultats sont fusionnés lors de l'appel à `dask.compute`, permettant aux opérations partagées d'être effectuées une seule fois au lieu de deux.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SB-HBHH9-SS-"
      },
      "source": [
        "### Exercice 3\n",
        "\n",
        "- Considérez le code ci-dessous qui calcule le retard moyen au départ par aéroport.\n",
        "- Parallélisez le code en utilisant Dask.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8O6F7OB-SS-"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "sum_delays = list()\n",
        "count_delays = list()\n",
        "\n",
        "for file_name in list_files:\n",
        "    pddf = pd.read_csv(file_name)\n",
        "    by_origin = pddf.groupby('Origin')\n",
        "    loc_total = by_origin.DepDelay.sum()\n",
        "    loc_count = by_origin.DepDelay.count()\n",
        "    sum_delays.append(loc_total)\n",
        "    count_delays.append(loc_count)\n",
        "\n",
        "total_delays = sum(sum_delays)\n",
        "n_flights = sum(count_delays)\n",
        "mean_delays = total_delays / n_flights\n",
        "print(\"Mean delays: {}\".format(mean_delays))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#VOTRE CODE ICI"
      ],
      "metadata": {
        "id": "wpMi9rgIH2vn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kX2LIZdV-STA"
      },
      "source": [
        "# <font color=\"red\">Ordonnanceurs de tâches</font>\n",
        "\n",
        "- Après que Dask a généré les graphes de tâches, il doit les exécuter sur du matériel parallèle.\n",
        "- C'est le rôle d'un ordonnanceur de tâches.\n",
        "- Il existe différents ordonnanceurs de tâches. Chacun consomme un graphe de tâches et calcule le même résultat, mais avec différentes caractéristiques de performance.\n",
        "\n",
        "![schedulers](https://docs.dask.org/en/latest/_images/dask-overview.svg)\n",
        "\n",
        "**Source de l'image** : [https://docs.dask.org/en/latest/](https://docs.dask.org/en/latest/)\n",
        "\n",
        "Les réseaux Dask sont composés de trois éléments :\n",
        "- **Ordonnanceur centralisé** : Gère les travailleurs et assigne les tâches qu'ils doivent accomplir.\n",
        "- **Travailleurs** : Sont des threads, processus, ou machines séparées dans un cluster. Ils exécutent les calculs du graphe de calcul : effectuent les calculs, conservent les résultats, et communiquent les résultats entre eux.\n",
        "- **Un ou plusieurs clients** : notebooks Jupyter ou scripts qui interagissent avec les utilisateurs et soumettent le travail à l'ordonnanceur pour exécution sur les travailleurs.\n",
        "\n",
        "![networks](https://miro.medium.com/max/700/0*9JHQAjTVoKbm2f4X.png)  \n",
        "**Source de l'image** : [Steven Gon](https://gongster.medium.com/dask-an-introduction-and-tutorial-b42f901bcff5)\n",
        "\n",
        "Pour exécuter les graphes de tâches, il existe deux types d'ordonnanceurs :\n",
        "* **Machine unique** : Fournit des fonctionnalités de base sur un processus local ou un pool de threads. Il est simple et économique à utiliser, mais ne peut être utilisé que sur une seule machine et ne scale pas.\n",
        "* **Distribué** : Offre plus de fonctionnalités, mais nécessite un peu plus d'effort pour la configuration. Il peut fonctionner localement ou distribué sur un cluster.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0AatZHa-STA"
      },
      "source": [
        "## <font color=\"blue\">Ordonnanceurs pour une machine unique</font>\n",
        "\n",
        "Considérez l'exemple suivant :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcWK238E-STA"
      },
      "outputs": [],
      "source": [
        "n = 10\n",
        "data = [i+1 for i in range(n)]\n",
        "\n",
        "out = list()\n",
        "for x in data:\n",
        "    y = dask.delayed(increment)(x)\n",
        "    z = dask.delayed(double)(y)\n",
        "    out.append(z)\n",
        "\n",
        "totald = 0\n",
        "for z in out:\n",
        "    totald = dask.delayed(add)(totald, z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckbGXSr--STA"
      },
      "source": [
        "**Synchonous**\n",
        "\n",
        "- L'ordonnanceur `synchrous` est une exécution mono-thread de tous les calculs dans le thread local, sans aucun parallélisme.\n",
        "- Il est utile pour le débogage ou le profilage.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPMiexZv-STA"
      },
      "outputs": [],
      "source": [
        "%time totald.compute(scheduler='synchronous')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FFn51TU-STA"
      },
      "source": [
        "**Threads locaux**\n",
        "\n",
        "Utilise `multiprocessing.pool.ThreadPool`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcTWDoCB-STA"
      },
      "source": [
        "Utiliser tous les coeurs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B48zHQbr-STA"
      },
      "outputs": [],
      "source": [
        "%time totald.compute(scheduler='threads')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSfvag_2-STA"
      },
      "source": [
        "Utiliser une partie des coeurs (NB : sur Colab vous n'avez que 2 coeurs, donc ça ne changera pas grand chose)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuVllFsr-STA"
      },
      "outputs": [],
      "source": [
        "%time totald.compute(scheduler='threads', num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bl3rk0YT-STB"
      },
      "source": [
        "Il y a aussi le mot clé `single-threaded`, équivalent à `num_workers = 1`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkEx_8Sd-STB"
      },
      "outputs": [],
      "source": [
        "%time totald.compute(scheduler='single-threaded')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_q0Eh_F-STB"
      },
      "source": [
        "**Processus locaux**\n",
        "\n",
        "- L'ordonnanceur multiprocessing exécute les calculs avec un `multiprocessing.Pool` local.\n",
        "- Chaque tâche et toutes ses dépendances sont envoyées à un processus local, exécutées, puis leur résultat est renvoyé au processus principal.\n",
        "- Le transfert de données vers les processus distants et en retour peut introduire des pénalités de performance, particulièrement lorsque les données transférées entre processus sont volumineuses.\n",
        "- L'ordonnanceur multiprocessing est un excellent choix lorsque les workflows sont relativement linéaires, sans transferts significatifs de données inter-tâches, et lorsque les entrées et sorties sont petites, comme des noms de fichiers et des comptes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgf3ouwm-STB"
      },
      "outputs": [],
      "source": [
        "import multiprocessing\n",
        "print (multiprocessing.cpu_count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrZqSW-l-STB"
      },
      "source": [
        "Utiliser tous les coeurs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vchqE__5-STB"
      },
      "outputs": [],
      "source": [
        "%time result = totald.compute(scheduler='processes')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpUCVr-p-STB"
      },
      "source": [
        "Utiliser un nombre spécifique de coeurs :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpjdnrTj-STB"
      },
      "outputs": [],
      "source": [
        "%time result = totald.compute(scheduler='processes', num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AagbVUAz-STB"
      },
      "source": [
        "### Threads ou Processus ?\n",
        "\n",
        "- **Utilisez l'ordonnanceur threadé** si votre calcul est dominé par du code non-Python, comme principalement le cas lors de l'utilisation de données numériques dans des tableaux NumPy, DataFrames Pandas, ou tout autre projet basé sur C/C++/Cython de l'écosystème.\n",
        "   - Il est léger.\n",
        "   - Peu de surcharge.\n",
        "   - Le transfert de données entre tâches n'est pas coûteux car tout se passe dans le même processus.\n",
        "- **Utilisez l'ordonnanceur multiprocessing** si votre calcul est dominé par le traitement d'objets Python purs comme des chaînes, dictionnaires ou listes.\n",
        "   - Il est léger.\n",
        "   - Chaque tâche et toutes ses dépendances sont envoyées à un processus local, exécutées, puis leur résultat est renvoyé au processus principal.\n",
        "   - Le transfert de données vers les processus distants et en retour peut introduire des pénalités de performance, particulièrement lorsque les données transférées entre processus sont volumineuses.\n",
        "   - Excellent choix quand les workflows sont relativement linéaires, sans transferts significatifs de données inter-tâches, et quand les entrées et sorties sont petites, comme des noms de fichiers et des comptes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93cTk5mo-STB"
      },
      "source": [
        "## <font color=\"blue\">Ordonnanceur distribué</font>\n",
        "\n",
        "- L'ordonnanceur distribué Dask peut être configuré sur un cluster ou exécuté localement sur une machine personnelle.\n",
        "- C'est un ordonnanceur de tâches dynamique, distribué et géré de manière centralisée.\n",
        "     - Le processus central `dask-scheduler` coordonne les actions de plusieurs processus `dask-worker` répartis sur plusieurs machines et les requêtes concurrentes de plusieurs clients.\n",
        "     - L'ordonnanceur est asynchrone et piloté par événements, répondant simultanément aux requêtes de calcul de multiples clients et suivant l'avancement de multiples travailleurs.\n",
        "     - La nature asynchrone et pilotée par événements le rend flexible pour gérer concurrentement une variété de charges de travail provenant de multiples utilisateurs tout en gérant une population de travailleurs fluide avec des pannes et ajouts.\n",
        "     - Les travailleurs communiquent entre eux pour le transfert massif de données via TCP.\n",
        "- Pour configurer `dask.distributed`, nous devons créer une instance client en appelant la classe `Client` depuis `dask.distributed`.\n",
        "- Cela créera en interne un ordonnanceur Dask et des travailleurs Dask.\n",
        "- Nous obtiendrons le **lien du tableau de bord** où nous pouvons analyser les tâches s'exécutant en parallèle.\n",
        "- Nous pouvons passer un nombre de travailleurs (via l'argument `n_workers`) et le nombre de threads par processus travailleur (via `threads_per_worker`).\n",
        "- Dès la création d'un client, Dask commence automatiquement à l'utiliser.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "t5OjTK-6-STC"
      },
      "outputs": [],
      "source": [
        "from dask.distributed import Client\n",
        "client = Client()\n",
        "client = Client(n_workers=3, threads_per_worker=4)\n",
        "client.cluster"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avN4B6mw-STC"
      },
      "source": [
        "Si vous êtes dans Google Colab, nous devons créer un tunnel pour rediriger le tableau de bord. Nous utiliserons le service [localXpose](https://localxpose.io/signup)\n",
        "\n",
        "C'est un service gratuit mais qui nécessite une inscription. Créez un compte et allez dans le menu \"Access\" pour copier votre propre token. Collez-le dans le code ci-dessous.\n",
        "\n",
        "**Si vous ne voulez pas créer un compte, vous pouvez sauter cette partie (ou alors executez Dask dans votre propre machine).**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install loclx-colab"
      ],
      "metadata": {
        "id": "hni3cS6NEB_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import loclx_colab.loclx as lx\n",
        "port = 8787 # The service port that you want to expose\n",
        "access_token = 'YOUR TOKEN' # Your LocalXpose token here\n",
        "url = lx.http_tunnel_start(port, access_token)\n",
        "print(f\"Your service is exposed to this URL: https://{url}\")"
      ],
      "metadata": {
        "id": "GQ1VdrKGEOJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parfois, l'URL ne s'affiche pas du premier coup. Vous pouvez imprimer la liste des adresses avec la commande ci-dessous. Copiez l'URL et collez-la dans un nouvel onglet de navigateur web.\n"
      ],
      "metadata": {
        "id": "iLm3zZ9CJRPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To list all live created tunels\n",
        "print(lx.http_tunnel_status())"
      ],
      "metadata": {
        "id": "aYVMLgoRGM3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iBbIXt8wJQWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Avec le dashboard, vous pouvez suivre l'éxécution des appels suivants :"
      ],
      "metadata": {
        "id": "MQcMe9SQJkCi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bSp1v2D-STC"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def random_slow_add(x, y):\n",
        "    time.sleep(random.randrange(3,10))\n",
        "    return x + y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsQyB-fP-STC"
      },
      "outputs": [],
      "source": [
        "results = list()\n",
        "\n",
        "for x in data:\n",
        "    y = dask.delayed(random_slow_add)(x, 1)\n",
        "    results.append(y)\n",
        "\n",
        "total = dask.delayed(sum)(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdrm0Zg1-STC"
      },
      "outputs": [],
      "source": [
        "%time result = total.compute()\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhhAtkcU-STC"
      },
      "source": [
        "Eteindre le cluster:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbX5qAxQ-STC"
      },
      "outputs": [],
      "source": [
        "client.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ54gJxw-STC"
      },
      "source": [
        "**<font color=\"red\">Points à considérer</font>**\n",
        "\n",
        "- Chaque tâche Dask a une surcharge (environ 1 ms). Si vous avez beaucoup de tâches, cette surcharge peut s'accumuler. Il est judicieux de donner à chaque tâche plus de quelques secondes de travail.\n",
        "- Pour mieux comprendre les performances de votre programme, consultez la documentation [Dask Performance Diagnostics](https://distributed.dask.org/en/latest/diagnosing-performance.html). Vous pouvez aussi visionner la [vidéo](https://docs.dask.org/en/stable/diagnostics-distributed.html) pour apprendre à grouper votre travail en moins de tâches plus substantielles. Cela peut signifier appeler les opérations paresseuses d'un coup au lieu individuellement. Cela peut aussi impliquer une repartition de vos DataFrame(s).\n",
        "- Une bonne règle empirique pour choisir le nombre de threads par travailleur Dask est la racine carrée du nombre de cœurs par nœud.\n",
        "     - En général, plus de threads par travailleur sont bons pour un programme qui passe la plupart de son temps dans NumPy, SciPy, Numba, etc., et moins de threads par travailleur sont meilleurs pour des programmes plus simples qui passent la plupart de leur temps dans l'interpréteur Python.\n",
        "- L'ordonnanceur Dask s'exécute sur un seul thread, donc lui assigner son propre nœud est un gaspillage.\n",
        "- Il n'y a pas de limite stricte à l'évolutivité de Dask. La surcharge des tâches finira toutefois par submerger votre calcul selon la durée de chaque tâche.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_sgdmqkIfRAl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noMtaFSH-SSx"
      },
      "source": [
        "## <font color=\"red\">Documents de Référence</font>\n",
        "\n",
        "- <a href=\"https://docs.dask.org/en/latest/why.html\">Pourquoi Dask ?</a>\n",
        "- <a href=\"https://github.com/dask/dask-tutorial\">Tutoriel</a>\n",
        "- <a href=\"https://www.manning.com/books/data-science-with-python-and-dask\">Data Science with Python and Dask</a>\n",
        "- <a href=\"https://www.manifold.ai/dask-and-machine-learning-preprocessing-tutorial\">Dask and Machine Learning: Preprocessing Tutorial</a>\n",
        "- <a href=\"https://carpentries-incubator.github.io/lesson-parallel-python/aio/index.html\">Parallel Programming in Python</a>\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Os0b7j0OfHQb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "adv_viz.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}