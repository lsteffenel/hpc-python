{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lsteffenel/hpc-python/blob/master/dask/06_futures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WPrgai8OYFm"
      },
      "source": [
        "<img src=\"https://github.com/lsteffenel/hpc-python/blob/master/dask/images/dask_horizontal.svg?raw=1\" align=\"right\" width=\"30%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lV_uAcQpOYFn"
      },
      "source": [
        "# Utilisation de Futures avec le mode Distributed"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install dask[complete]"
      ],
      "metadata": {
        "id": "HOLWJpHlOegA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5_CGMmkOYFn"
      },
      "source": [
        "## Distributed futures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zINc7rv1OYFn"
      },
      "outputs": [],
      "source": [
        "from dask.distributed import Client\n",
        "c = Client(n_workers=4)\n",
        "c.cluster"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLupP0MLOYFo"
      },
      "source": [
        "Dans le chapitre précédent, nous avons montré que l'exécution d'un calcul (créé avec `delayed`) avec l'exécuteur distribué est identique à tout autre exécuteur. Cependant, nous avons maintenant accès à une fonctionnalité supplémentaire et au contrôle sur les données maintenues en mémoire.\n",
        "\n",
        "Pour commencer, l'interface `futures` (dérivée de `concurrent.futures` intégré) permet une fonctionnalité de type map-reduce. Nous pouvons soumettre des fonctions individuelles pour évaluation avec un ensemble d'entrées, ou les évaluer sur une séquence d'entrées avec `submit()` et `map()`. Notez que l'appel retourne immédiatement, fournissant un ou plusieurs *futures*, dont le statut commence en \"pending\" puis devient \"finished\". Il n'y a pas de blocage de la session Python locale.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilgmrjK6OYFo"
      },
      "source": [
        "Voici le plus simple exemple de `submit` en action :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ghMA5SUOYFo"
      },
      "outputs": [],
      "source": [
        "def inc(x):\n",
        "    return x + 1\n",
        "\n",
        "fut = c.submit(inc, 1)\n",
        "fut"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJfE-cfJOYFo"
      },
      "source": [
        "Nous pouvons ré-exécuter la cellule suivante aussi souvent que nous le souhaitons pour sonder le statut du future. Cela pourrait bien sûr être fait dans une boucle, en pausant brièvement à chaque itération. Nous pourrions continuer notre travail, ou visualiser une barre de progression du travail en cours, ou forcer l'attente jusqu'à ce que le future soit prêt.\n",
        "\n",
        "Si vous consultez le dashboard, le tableau de bord `status` a gagné un nouvel élément dans le flux de tâches, indiquant que `inc()` s'est terminé, et la section de progression pour le problème montre une tâche terminée et maintenue en mémoire.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8RZkej6OYFo"
      },
      "outputs": [],
      "source": [
        "fut"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehn5u5scOYFp"
      },
      "source": [
        "Possibles alternatives que vous pourriez explorer :\n",
        "```python\n",
        "from dask.distributed import wait, progress\n",
        "progress(fut)\n",
        "```\n",
        "afficherait une barre de progression dans ce notebook, plutôt que d’avoir à aller sur le tableau de bord. Cette barre de progression est également asynchrone et ne bloque pas l’exécution des autres morceaux de code entre‑temps.\n",
        "\n",
        "```python\n",
        "wait(fut)\n",
        "```\n",
        "bloquerait et forcerait le notebook à attendre jusqu’à ce que le calcul référencé par fut soit terminé. Cependant, notez que le résultat de `inc()` réside déjà dans le cluster ; exécuter le calcul maintenant ne prendrait **aucun temps**, car Dask remarque que l’on demande le résultat d’un calcul dont il a déjà connaissance. On y reviendra plus tard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxljuiePOYFp"
      },
      "outputs": [],
      "source": [
        "# grab the information back - this blocks if fut is not ready\n",
        "c.gather(fut)\n",
        "# equivalent action when only considering a single future\n",
        "# fut.result()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvukf-hYOYFp"
      },
      "source": [
        "Ici, nous voyons une autre façon d'exécuter des tâches sur le cluster : lorsque vous soumettez ou mappez avec les entrées sous forme de *futures*, le *calcul se déplace vers les données* plutôt que l'inverse, et le client, dans la session Python locale, n'a jamais besoin de voir les valeurs intermédiaires. Cela est similaire à la construction du graphe avec `delayed`, et en effet, `delayed` peut être utilisé en combinaison avec les *futures*. Ici, nous utilisons l'objet `delayed` `total` d'avant.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54uovLMLOYFp"
      },
      "outputs": [],
      "source": [
        "# Some trivial work that takes time\n",
        "# repeated from the Distributed chapter.\n",
        "\n",
        "from dask import delayed\n",
        "import time\n",
        "\n",
        "def inc(x):\n",
        "    time.sleep(5)\n",
        "    return x + 1\n",
        "\n",
        "def dec(x):\n",
        "    time.sleep(3)\n",
        "    return x - 1\n",
        "\n",
        "def add(x, y):\n",
        "    time.sleep(7)\n",
        "    return x + y\n",
        "\n",
        "x = delayed(inc)(1)\n",
        "y = delayed(dec)(2)\n",
        "total = delayed(add)(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWEqZbNAOYFp"
      },
      "outputs": [],
      "source": [
        "# notice the difference from total.compute()\n",
        "# notice that this cell completes immediately\n",
        "fut = c.compute(total)\n",
        "fut"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4H3eL56KOYFp"
      },
      "outputs": [],
      "source": [
        "c.gather(fut) # waits until result is ready"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKwGZ3FyOYFp"
      },
      "source": [
        "### `Client.submit`\n",
        "\n",
        "`submit` prend une fonction et des arguments, les pousse vers le cluster, et retourne un *Future* représentant le résultat à calculer. La fonction est passée à un processus worker pour évaluation. Notez que cette cellule retourne immédiatement, alors que le calcul peut encore être en cours sur le cluster.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mP1mz0HyOYFp"
      },
      "outputs": [],
      "source": [
        "fut = c.submit(inc, 1)\n",
        "fut"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaBjq4YNOYFq"
      },
      "source": [
        "Cela ressemble beaucoup à faire un `compute()`, ci-dessus, sauf que maintenant nous passons directement la fonction et les arguments au cluster. Pour quiconque habitué à `concurrent.futures`, cela paraîtra familier. Ce nouveau `fut` se comporte de la même manière que celui d'au-dessus. Notez que nous avons maintenant écrasé la définition précédente de `fut`, qui sera collectée par le ramasse-miettes, et, par conséquent, ce résultat précédent est libéré par le cluster.\n",
        "\n",
        "### Exercice : Reconstruire le calcul *delayed* ci-dessus en utilisant `Client.submit` à la place\n",
        "\n",
        "Les arguments passés à `submit` peuvent être des *futures* d'autres opérations `submit` ou des objets *delayed*. Le premier cas en particulier démontre le concept de *déplacer le calcul vers les données*, qui est l'un des éléments les plus puissants de la programmation avec Dask.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_9xeMHkOYFq"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "s1ywOquOOYFq"
      },
      "outputs": [],
      "source": [
        "x = c.submit(inc, 1)\n",
        "y = c.submit(dec, 2)\n",
        "total = c.submit(add, x, y)\n",
        "\n",
        "print(total)     # This is still a future\n",
        "c.gather(total)   # This blocks until the computation has finished\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVooei-lOYFq"
      },
      "source": [
        "Chaque *future* représente un résultat détenu, ou en cours d'évaluation par le cluster. Ainsi, nous pouvons contrôler le cache des valeurs intermédiaires - lorsqu'un *future* n'est plus référencé, sa valeur est oubliée. Dans la solution, ci-dessus, des *futures* sont conservés pour chacun des appels de fonction. Ces résultats n'auraient pas besoin d'être réévalués si nous choisissions de soumettre plus de travail les nécessitant.\n",
        "\n",
        "Nous pouvons explicitement passer des données de notre session locale vers le cluster en utilisant `scatter()`, mais il est généralement préférable de construire des fonctions qui chargent les données directement dans les *workers* eux-mêmes, afin qu'il n'y ait pas besoin de sérialiser et communiquer les données. La plupart des fonctions de chargement dans Dask, telles que `dd.read_csv`, fonctionnent de cette manière. De même, nous ne voulons normalement pas `gather()` des résultats trop volumineux en mémoire.\n",
        "\n",
        "L'[API complète](http://distributed.readthedocs.io/en/latest/api.html) du planificateur distribué donne des détails sur l'interaction avec le cluster, qui, rappelez-vous, peut être sur votre machine locale ou éventuellement sur une ressource de calcul massive.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAGx8jigOYFq"
      },
      "source": [
        "L'API *futures* offre un style de soumission de travail qui peut facilement émuler le paradigme *map/reduce* (voir `c.map()`) qui peut être familier à beaucoup de personnes. Les résultats intermédiaires, représentés par des *futures*, peuvent être passés à de nouvelles tâches sans avoir à les récupérer localement depuis le cluster, et du nouveau travail peut être assigné pour travailler sur la sortie de jobs précédents qui n'ont même pas encore commencé.\n",
        "\n",
        "Généralement, toute opération Dask qui est exécutée avec `.compute()` peut être soumise pour une exécution asynchrone en utilisant `c.compute()` à la place, et cela s'applique à toutes les collections. Voici un exemple avec le calcul vu précédemment dans le chapitre Bag. Nous avons remplacé la méthode `.compute()` par la version client distribué, donc, encore une fois, nous pourrions continuer à soumettre plus de travail (peut-être basé sur le résultat du calcul), ou, dans la cellule suivante, suivre la progression du calcul. Une barre de progression similaire apparaît dans la page d'interface de surveillance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNn4iC0nOYFr"
      },
      "source": [
        "## Calcul asynchrone\n",
        "<img style=\"float: right;\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/32/Rosenbrock_function.svg/450px-Rosenbrock_function.svg.png\" height=200 width=200>\n",
        "\n",
        "Un avantage de l'utilisation de l'API *futures* est que vous pouvez avoir des calculs dynamiques qui s'ajustent au fur et à mesure que les choses progressent. Ici, nous implémentons une recherche naïve simple en parcourant les résultats au fur et à mesure qu'ils arrivent, et soumettons de nouveaux points à calculer tandis que d'autres sont encore en cours d'exécution.\n",
        "\n",
        "En observant le [tableau de bord de diagnostic](../../9002/status) pendant l'exécution, vous pouvez voir que des calculs sont exécutés concurremment tandis que d'autres sont soumis. Cette flexibilité peut être utile pour des algorithmes parallèles qui nécessitent un certain niveau de synchronisation.\n",
        "\n",
        "Réalisons une minimisation très simple en utilisant la programmation dynamique. La fonction d'intérêt est connue sous le nom de Rosenbrock :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrCKpymCOYFr"
      },
      "outputs": [],
      "source": [
        "# a simple function with interesting minima\n",
        "import time\n",
        "\n",
        "def rosenbrock(point):\n",
        "    \"\"\"Compute the rosenbrock function and return the point and result\"\"\"\n",
        "    time.sleep(0.1)\n",
        "    score = (1 - point[0])**2 + 2 * (point[1] - point[0]**2)**2\n",
        "    return point, score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9qTnLMBOYFs"
      },
      "source": [
        "Configuration initiale, incluant la création d'une figure graphique. Nous utilisons Bokeh pour cela, qui permet la mise à jour dynamique de la figure au fur et à mesure que les résultats arrivent.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7auUhH9OYFs"
      },
      "outputs": [],
      "source": [
        "from bokeh.io import output_notebook, push_notebook\n",
        "from bokeh.models.sources import ColumnDataSource\n",
        "from bokeh.plotting import figure, show\n",
        "import numpy as np\n",
        "output_notebook()\n",
        "\n",
        "# set up plot background\n",
        "N = 500\n",
        "x = np.linspace(-5, 5, N)\n",
        "y = np.linspace(-5, 5, N)\n",
        "xx, yy = np.meshgrid(x, y)\n",
        "d = (1 - xx)**2 + 2 * (yy - xx**2)**2\n",
        "d = np.log(d)\n",
        "\n",
        "p = figure(x_range=(-5, 5), y_range=(-5, 5))\n",
        "p.image(image=[d], x=-5, y=-5, dw=10, dh=10, palette=\"Spectral11\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUzV0-ubOYFs"
      },
      "source": [
        "Nous commençons avec un point en (0, 0), et dispersons aléatoirement des points de test autour de lui. Chaque évaluation prend ~100 ms, et au fur et à mesure que les résultats arrivent, nous vérifions si nous avons un nouveau meilleur point, et choisissons des points aléatoires autour de ce nouveau meilleur point, tandis que la boîte de recherche se rétrécit.\n",
        "\n",
        "Nous affichons la valeur de la fonction et l'emplacement du meilleur actuel à chaque fois que nous avons une nouvelle meilleure valeur.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXPEuPaSOYFs"
      },
      "outputs": [],
      "source": [
        "from dask.distributed import as_completed\n",
        "from random import uniform\n",
        "\n",
        "scale = 5                  # Intial random perturbation scale\n",
        "best_point = (0, 0)        # Initial guess\n",
        "best_score = float('inf')  # Best score so far\n",
        "startx = [uniform(-scale, scale) for _ in range(10)]\n",
        "starty = [uniform(-scale, scale) for _ in range(10)]\n",
        "\n",
        "# set up plot\n",
        "source = ColumnDataSource({'x': startx, 'y': starty, 'c': ['grey'] * 10})\n",
        "p.circle(source=source, x='x', y='y', color='c', radius=0.1)\n",
        "t = show(p, notebook_handle=True)\n",
        "\n",
        "# initial 10 random points\n",
        "futures = [c.submit(rosenbrock, (x, y)) for x, y in zip(startx, starty)]\n",
        "iterator = as_completed(futures)\n",
        "\n",
        "for res in iterator:\n",
        "    # take a completed point, is it an improvement?\n",
        "    point, score = res.result()\n",
        "    if score < best_score:\n",
        "        best_score, best_point = score, point\n",
        "        print(score, point)\n",
        "\n",
        "    x, y = best_point\n",
        "    newx, newy = (x + uniform(-scale, scale), y + uniform(-scale, scale))\n",
        "\n",
        "    # update plot\n",
        "    source.stream({'x': [newx], 'y': [newy], 'c': ['grey']}, rollover=20)\n",
        "    push_notebook(document=t)\n",
        "\n",
        "    # add new point, dynamically, to work on the cluster\n",
        "    new_point = c.submit(rosenbrock, (newx, newy))\n",
        "    iterator.add(new_point)  # Start tracking new task as well\n",
        "\n",
        "    # Narrow search and consider stopping\n",
        "    scale *= 0.99\n",
        "    if scale < 0.001:\n",
        "        break\n",
        "point"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nk8tZbL0iQvo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}